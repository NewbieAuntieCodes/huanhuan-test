// FIX: Changed React import from a named import to a default import to correctly resolve the React namespace for types like React.ChangeEvent.
import React, { useState, useCallback, useMemo } from 'react';
import { Project, Character, Chapter, ScriptLine } from '../../../types';
import * as mm from 'music-metadata-browser';
import { bufferToWav } from '../../../lib/wavEncoder';

interface UseAudioFileMatcherProps {
  currentProject: Project | undefined;
  characters: Character[];
  assignAudioToLine: (projectId: string, chapterId: string, lineId: string, audioBlob: Blob) => Promise<void>;
}

const parseChapterIdentifier = (identifier: string): number[] => {
    if (identifier.includes('-')) {
        const parts = identifier.split('-').map(p => parseInt(p, 10));
        if (parts.length === 2 && !isNaN(parts[0]) && !isNaN(parts[1])) {
            const [start, end] = parts;
            const range = [];
            for (let i = start; i <= end; i++) {
                range.push(i);
            }
            return range;
        }
    }
    const num = parseInt(identifier, 10);
    if (!isNaN(num)) {
        return [num];
    }
    return [];
};

// è§£æAdobe Audition XMPæ ¼å¼çš„CuePointæ ‡è®°
const parseXmpCuePoints = (metadata: any, audioDuration: number): { startTime: number; endTime: number }[] | null => {
    try {
        // ä» native æ ‡ç­¾ä¸­æŸ¥æ‰¾æ‰€æœ‰ PRIV å¸§
        let privTags: any[] = [];

        // æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„ ID3 ç‰ˆæœ¬
        const id3Versions = ['ID3v2.3', 'ID3v2.4', 'ID3v2.2', 'ID3v2'];

        for (const version of id3Versions) {
            const nativeTags = metadata.native?.[version];
            if (Array.isArray(nativeTags)) {
                // å¦‚æœæ˜¯æ•°ç»„ï¼ŒæŸ¥æ‰¾ id === 'PRIV' çš„å…ƒç´ 
                const privFrames = nativeTags.filter((tag: any) => tag?.id === 'PRIV');
                privTags.push(...privFrames);
            } else if (nativeTags?.PRIV) {
                // å¦‚æœæ˜¯å¯¹è±¡ï¼Œç›´æ¥è·å– PRIV
                const privData = Array.isArray(nativeTags.PRIV) ? nativeTags.PRIV : [nativeTags.PRIV];
                privTags.push(...privData);
            }
        }

        if (privTags.length === 0) {
            console.log('æœªæ‰¾åˆ°PRIVæ ‡ç­¾');
            return null;
        }

        console.log(`æ‰¾åˆ° ${privTags.length} ä¸ªPRIVæ ‡ç­¾`);

        // æŸ¥æ‰¾XMPç§æœ‰æ ‡ç­¾
        const xmpTag = privTags.find((tag: any) => {
            // æ£€æŸ¥å¤šç§å¯èƒ½çš„XMPæ ‡è¯†
            if (tag?.value?.owner_identifier === 'XMP') return true;
            if (tag?.owner_identifier === 'XMP') return true;
            if (typeof tag === 'string' && tag.includes('xmpmeta')) return true;
            if (tag?.description && tag.description.includes('xmpmeta')) return true;
            // æ£€æŸ¥tag.valueæ˜¯å¦ä¸ºå­—ç¬¦ä¸²ä¸”åŒ…å«XMP
            if (typeof tag?.value === 'string' && tag.value.includes('xmpmeta')) return true;
            // æ£€æŸ¥dataå­—æ®µ
            if (tag?.value?.data && typeof tag.value.data === 'string' && tag.value.data.includes('xmpmeta')) return true;
            return false;
        });

        if (!xmpTag) {
            console.log('æœªæ‰¾åˆ°XMPæ ‡ç­¾');
            return null;
        }

        console.log('æ‰¾åˆ°XMPæ ‡ç­¾:', xmpTag);

        // è·å–XMPå­—ç¬¦ä¸² - å°è¯•å¤šç§å¯èƒ½çš„æ•°æ®ä½ç½®
        let xmpString = '';
        if (typeof xmpTag === 'string') {
            xmpString = xmpTag;
        } else if (typeof xmpTag.value === 'string') {
            xmpString = xmpTag.value;
        } else if (xmpTag.value?.data) {
            if (typeof xmpTag.value.data === 'string') {
                xmpString = xmpTag.value.data;
            } else if (xmpTag.value.data instanceof Uint8Array || xmpTag.value.data instanceof Buffer) {
                // å°†å­—èŠ‚æ•°ç»„è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                xmpString = new TextDecoder('utf-8').decode(xmpTag.value.data);
            }
        } else if (xmpTag.description) {
            xmpString = xmpTag.description;
        }

        if (!xmpString) {
            console.log('XMPæ ‡ç­¾ä¸­æ²¡æœ‰æ•°æ®');
            return null;
        }

        console.log(`XMPå­—ç¬¦ä¸²é•¿åº¦: ${xmpString.length}`);
        console.log('XMPå­—ç¬¦ä¸²ç‰‡æ®µ:', xmpString.substring(0, 200));

        // ç®€å•çš„æ­£åˆ™è¡¨è¾¾å¼è§£æXMPä¸­çš„CuePointæ ‡è®°
        // åŒ¹é… xmpDM:startTime="æ•°å­—"
        const startTimeRegex = /xmpDM:startTime="(\d+)"/g;
        const frameRateRegex = /xmpDM:frameRate="f(\d+)"/;

        // æå–é‡‡æ ·ç‡
        const frameRateMatch = xmpString.match(frameRateRegex);
        const sampleRate = frameRateMatch ? parseInt(frameRateMatch[1], 10) : 48000; // é»˜è®¤48kHz

        // æå–æ‰€æœ‰startTime
        const startTimes: number[] = [];
        let match;
        while ((match = startTimeRegex.exec(xmpString)) !== null) {
            startTimes.push(parseInt(match[1], 10));
        }

        if (startTimes.length === 0) {
            return null;
        }

        // æ’åº
        startTimes.sort((a, b) => a - b);

        // å¦‚æœç¬¬ä¸€ä¸ªæ ‡è®°ä¸æ˜¯ä» 0 å¼€å§‹ï¼Œæ·»åŠ ä¸€ä¸ªèµ·å§‹æ ‡è®°
        if (startTimes.length > 0 && startTimes[0] > 0) {
            startTimes.unshift(0);
            console.log('æ·»åŠ èµ·å§‹æ ‡è®°ï¼ˆæ—¶é—´ 0ï¼‰');
        }

        // åˆ›å»ºæ—¶é—´æ®µï¼šä»æ¯ä¸ªmarkeråˆ°ä¸‹ä¸€ä¸ªmarkerï¼ˆæˆ–éŸ³é¢‘ç»“æŸï¼‰
        const segments: { startTime: number; endTime: number }[] = [];
        for (let i = 0; i < startTimes.length; i++) {
            const startTime = startTimes[i] / sampleRate;
            const endTime = i < startTimes.length - 1
                ? startTimes[i + 1] / sampleRate
                : audioDuration;

            segments.push({ startTime, endTime });
        }

        console.log(`ä»XMPä¸­è§£æåˆ° ${segments.length} ä¸ªéŸ³é¢‘æ®µè½ï¼ˆåŒ…å«èµ·å§‹æ®µï¼‰`);
        return segments;

    } catch (error) {
        console.error('è§£æXMP CuePointæ ‡è®°å¤±è´¥:', error);
        return null;
    }
};

export const useAudioFileMatcher = ({
  currentProject,
  characters,
  assignAudioToLine,
}: UseAudioFileMatcherProps) => {
  const [isCvMatchLoading, setIsCvMatchLoading] = useState(false);
  const [isCharacterMatchLoading, setIsCharacterMatchLoading] = useState(false);
  const [isChapterMatchLoading, setIsChapterMatchLoading] = useState(false);

  const nonAudioCharacterIds = useMemo(() => {
    return characters
      .filter(c => c.name === '[é™éŸ³]' || c.name === 'éŸ³æ•ˆ')
      .map(c => c.id);
  }, [characters]);

  const handleFileSelectionForCvMatch = useCallback(async (event: React.ChangeEvent<HTMLInputElement>) => {
      console.log('ğŸ”µ handleFileSelectionForCvMatch è¢«è°ƒç”¨');
      const files = event.target.files;
      console.log('ğŸ“ é€‰æ‹©çš„æ–‡ä»¶æ•°é‡:', files?.length);

      if (!files || files.length === 0 || !currentProject) {
          console.log('âš ï¸ æ²¡æœ‰æ–‡ä»¶æˆ–æ²¡æœ‰é¡¹ç›®');
          return;
      }

      console.log('ğŸš€ å¼€å§‹å¤„ç†æ–‡ä»¶...');

      // æ£€æŸ¥ Buffer æ˜¯å¦å¯ç”¨
      if (typeof window.Buffer === 'undefined') {
          console.error('âŒ Buffer æœªå®šä¹‰ï¼è¿™å¯èƒ½å¯¼è‡´ music-metadata-browser æ— æ³•å·¥ä½œ');
          alert('é”™è¯¯ï¼šBuffer æœªåŠ è½½ã€‚è¯·åˆ·æ–°é¡µé¢é‡è¯•ã€‚');
          return;
      } else {
          console.log('âœ… Buffer å·²åŠ è½½');
      }

      setIsCvMatchLoading(true);

      let totalMatchedCount = 0;
      let totalMissedCount = 0;
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      console.log('ğŸµ AudioContext åˆ›å»ºæˆåŠŸ');

      for (const file of Array.from(files)) {
          console.log('ğŸ“„ å¤„ç†æ–‡ä»¶:', file.name, 'å¤§å°:', file.size, 'bytes');
          const nameWithoutExt = file.name.substring(0, file.name.lastIndexOf('.'));
          const parts = nameWithoutExt.split('_');
          console.log('ğŸ“ æ–‡ä»¶åéƒ¨åˆ†:', parts);

          if (parts.length !== 2) { // Expecting chapter_cv
              console.warn(`âš ï¸ è·³è¿‡ï¼šæ–‡ä»¶åæ ¼å¼ä¸æ­£ç¡®: ${file.name} (æœŸæœ›æ ¼å¼: ç« èŠ‚_CVå.mp3)`);
              continue;
          }

          const chapterIdentifier = parts[0];
          const cvName = parts[1];
          
          try {
              // 1. Find target script lines for this CV and chapter range
              const targetCharacterIds = new Set(
                  characters.filter(c => c.cvName === cvName && c.status !== 'merged').map(c => c.id)
              );

              if (targetCharacterIds.size === 0) {
                  console.warn(`No characters found for CV: ${cvName}`);
                  continue;
              }

              const chapterMatchers = parseChapterIdentifier(chapterIdentifier);
              const targetChapters = currentProject.chapters.filter((chapter, index) => {
                  const chapterNumber = index + 1;
                  return chapterMatchers.includes(chapterNumber);
              });

              if (targetChapters.length === 0) {
                  console.warn(`No chapters found for identifier: ${chapterIdentifier}`);
                  continue;
              }

              const targetLines: { line: ScriptLine; chapterId: string }[] = [];
              for (const chapter of targetChapters) {
                  for (const line of chapter.scriptLines) {
                      if (line.characterId && targetCharacterIds.has(line.characterId) && !nonAudioCharacterIds.includes(line.characterId)) {
                          targetLines.push({ line, chapterId: chapter.id });
                      }
                  }
              }
              
              if (targetLines.length === 0) {
                  console.warn(`No lines found for CV ${cvName} in chapters ${chapterIdentifier}`);
                  continue;
              }

              // 2. Parse MP3 markers - æ”¯æŒID3v2 CHAPå’ŒAdobe XMP CuePoint
              console.log('ğŸ” å¼€å§‹è§£æ MP3 å…ƒæ•°æ®...');
              let metadata;
              try {
                  metadata = await mm.parseBlob(file);
                  console.log('âœ… å…ƒæ•°æ®è§£ææˆåŠŸ');
              } catch (parseError) {
                  console.error('âŒ è§£æå…ƒæ•°æ®å¤±è´¥:', parseError);
                  console.error('è¿™å¯èƒ½æ˜¯ç”±äºæµè§ˆå™¨ç¯å¢ƒçš„å…¼å®¹æ€§é—®é¢˜');
                  console.error('å»ºè®®ï¼š1) ä½¿ç”¨å…¶ä»–æµè§ˆå™¨  2) ä½¿ç”¨æŒ‰è§’è‰²åŒ¹é…ä¸Šä¼ å·²åˆ†æ®µçš„éŸ³é¢‘æ–‡ä»¶');

                  // æ˜¾ç¤ºå‹å¥½çš„é”™è¯¯æç¤º
                  alert(`æ— æ³•è§£æ MP3 æ–‡ä»¶ "${file.name}" çš„å…ƒæ•°æ®ã€‚\n\nå¯èƒ½çš„åŸå› ï¼š\n- å½“å‰ç¯å¢ƒä¸æ”¯æŒæ­¤åŠŸèƒ½\n- MP3 æ–‡ä»¶æ ¼å¼é—®é¢˜\n\nå»ºè®®ï¼š\n- ä½¿ç”¨"æŒ‰è§’è‰²åŒ¹é…"åŠŸèƒ½ä¸Šä¼ å·²åˆ†æ®µçš„éŸ³é¢‘æ–‡ä»¶\n- æˆ–åœ¨æœ¬åœ°ç¯å¢ƒè¿è¡Œ`);

                  totalMissedCount += targetLines.length;
                  continue;
              }

              // è°ƒè¯•ï¼šæ‰“å°å®Œæ•´çš„ metadata ç»“æ„
              console.log('å®Œæ•´å…ƒæ•°æ®:', metadata);
              console.log('metadata.common:', metadata.common);
              console.log('metadata.native:', metadata.native);
              console.log('metadata.common.chapters:', metadata.common.chapters);

              // è¯¦ç»†æŸ¥çœ‹ native æ ‡ç­¾
              if (metadata.native) {
                  Object.keys(metadata.native).forEach(key => {
                      console.log(`metadata.native['${key}']:`, metadata.native[key]);
                  });
              }

              let audioSegments: { startTime: number; endTime: number }[] = [];

              // é¦–å…ˆå°è¯•ä» metadata.common.chapters è¯»å–ï¼ˆmusic-metadata-browser ä¼šè‡ªåŠ¨è§£æ CHAP/CTOCï¼‰
              const chapters = metadata.common.chapters || [];

              if (chapters.length > 0) {
                  // ä½¿ç”¨è§£æå¥½çš„ç« èŠ‚ä¿¡æ¯
                  audioSegments = chapters.map(chapter => ({
                      startTime: chapter.startTime / 1000,  // å·²ç»æ˜¯æ¯«ç§’ï¼Œè½¬æ¢ä¸ºç§’
                      endTime: chapter.endTime / 1000,
                  }));
                  console.log(`ä»ç« èŠ‚ä¿¡æ¯ä¸­è§£æåˆ° ${audioSegments.length} ä¸ªç« èŠ‚æ ‡è®°`);
              } else {
                  // å°è¯•è§£æAdobe Audition XMP CuePointæ ‡è®°
                  const audioDuration = metadata.format.duration || 0;
                  const xmpSegments = parseXmpCuePoints(metadata, audioDuration);

                  if (xmpSegments && xmpSegments.length > 0) {
                      audioSegments = xmpSegments;
                  } else {
                      totalMissedCount += targetLines.length;
                      console.warn(`File ${file.name} has no chapter markers (neither CHAP nor XMP CuePoint).`);
                      continue;
                  }
              }

              // 3. Decode audio and split into blobs
              const mainAudioBuffer = await audioContext.decodeAudioData(await file.arrayBuffer());

              const limit = Math.min(targetLines.length, audioSegments.length);
              
              for (let i = 0; i < limit; i++) {
                  const segment = audioSegments[i];
                  const lineInfo = targetLines[i];
                  
                  const { startTime, endTime } = segment;
                  const duration = endTime - startTime;
                  if (duration <= 0) continue;

                  const startSample = Math.floor(startTime * mainAudioBuffer.sampleRate);
                  const endSample = Math.floor(endTime * mainAudioBuffer.sampleRate);
                  const numSamples = endSample - startSample;
                  
                  const segmentBuffer = audioContext.createBuffer(
                      mainAudioBuffer.numberOfChannels,
                      numSamples,
                      mainAudioBuffer.sampleRate
                  );

                  for (let channel = 0; channel < mainAudioBuffer.numberOfChannels; channel++) {
                      const channelData = mainAudioBuffer.getChannelData(channel);
                      const segmentData = channelData.subarray(startSample, endSample);
                      segmentBuffer.copyToChannel(segmentData, channel);
                  }

                  const segmentBlob = bufferToWav(segmentBuffer);

                  // 4. Assign split blob to line
                  await assignAudioToLine(currentProject.id, lineInfo.chapterId, lineInfo.line.id, segmentBlob);
                  totalMatchedCount++;
              }
              totalMissedCount += Math.abs(targetLines.length - audioSegments.length);

          } catch (error) {
              console.error(`Error processing file ${file.name}:`, error);
          }
      }

      await audioContext.close();
      setIsCvMatchLoading(false);
      alert(`æŒ‰CVåŒ¹é…å®Œæˆã€‚\næˆåŠŸåŒ¹é…: ${totalMatchedCount} æ¡éŸ³è½¨\næœªåŒ¹é…/å¤±è´¥: ${totalMissedCount}`);
  
      if (event.target) {
          event.target.value = '';
      }
  }, [currentProject, characters, assignAudioToLine, nonAudioCharacterIds]);
  
  const handleFileSelectionForCharacterMatch = useCallback(async (event: React.ChangeEvent<HTMLInputElement>) => {
      console.log('ğŸ”µ handleFileSelectionForCharacterMatch è¢«è°ƒç”¨');
      const files = event.target.files;
      console.log('ğŸ“ é€‰æ‹©çš„æ–‡ä»¶æ•°é‡:', files?.length);

      if (!files || files.length === 0 || !currentProject) {
          console.log('âš ï¸ æ²¡æœ‰æ–‡ä»¶æˆ–æ²¡æœ‰é¡¹ç›®');
          return;
      }

      console.log('ğŸš€ å¼€å§‹å¤„ç†æ–‡ä»¶...');
      if (typeof window.Buffer === 'undefined') {
          console.error('âŒ Buffer æœªå®šä¹‰ï¼');
          alert('é”™è¯¯ï¼šBuffer æœªåŠ è½½ã€‚è¯·åˆ·æ–°é¡µé¢é‡è¯•ã€‚');
          return;
      }

      setIsCharacterMatchLoading(true);

      let totalMatchedCount = 0;
      let totalMissedCount = 0;
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      console.log('ğŸµ AudioContext åˆ›å»ºæˆåŠŸ');

      for (const file of Array.from(files)) {
          console.log('ğŸ“„ å¤„ç†æ–‡ä»¶:', file.name, 'å¤§å°:', file.size, 'bytes');
          const nameWithoutExt = file.name.substring(0, file.name.lastIndexOf('.'));
          const parts = nameWithoutExt.split('_');
          console.log('ğŸ“ æ–‡ä»¶åéƒ¨åˆ†:', parts);

          if (parts.length !== 2) { // Expecting chapter_characterName
              console.warn(`âš ï¸ è·³è¿‡ï¼šæ–‡ä»¶åæ ¼å¼ä¸æ­£ç¡®: ${file.name} (æœŸæœ›æ ¼å¼: ç« èŠ‚_è§’è‰²å.mp3)`);
              continue;
          }

          const chapterIdentifier = parts[0];
          const characterName = parts[1];
          
          try {
              // 1. Find target script lines for this character and chapter range
              const targetCharacterIds = new Set(
                  characters.filter(c => c.name === characterName && c.status !== 'merged').map(c => c.id)
              );

              if (targetCharacterIds.size === 0) {
                  console.warn(`No characters found for name: ${characterName}`);
                  continue;
              }

              const chapterMatchers = parseChapterIdentifier(chapterIdentifier);
              const targetChapters = currentProject.chapters.filter((chapter, index) => {
                  const chapterNumber = index + 1;
                  return chapterMatchers.includes(chapterNumber);
              });

              if (targetChapters.length === 0) {
                  console.warn(`No chapters found for identifier: ${chapterIdentifier}`);
                  continue;
              }

              const targetLines: { line: ScriptLine; chapterId: string }[] = [];
              for (const chapter of targetChapters) {
                  for (const line of chapter.scriptLines) {
                      if (line.characterId && targetCharacterIds.has(line.characterId) && !nonAudioCharacterIds.includes(line.characterId)) {
                          targetLines.push({ line, chapterId: chapter.id });
                      }
                  }
              }
              
              if (targetLines.length === 0) {
                  console.warn(`No lines found for character ${characterName} in chapters ${chapterIdentifier}`);
                  continue;
              }

              // 2. Parse audio markers
              console.log('ğŸ” å¼€å§‹è§£æéŸ³é¢‘å…ƒæ•°æ®...');
              let metadata;
              try {
                  metadata = await mm.parseBlob(file);
                  console.log('âœ… å…ƒæ•°æ®è§£ææˆåŠŸ');
              } catch (parseError) {
                  console.error('âŒ è§£æå…ƒæ•°æ®å¤±è´¥:', parseError);
                  alert(`æ— æ³•è§£æéŸ³é¢‘æ–‡ä»¶ "${file.name}" çš„å…ƒæ•°æ®ã€‚`);
                  totalMissedCount += targetLines.length;
                  continue;
              }

              let audioSegments: { startTime: number; endTime: number }[] = [];
              const chapters = metadata.common.chapters || [];

              if (chapters.length > 0) {
                  audioSegments = chapters.map(chapter => ({
                      startTime: chapter.startTime / 1000,
                      endTime: chapter.endTime / 1000,
                  }));
                  console.log(`ä»ç« èŠ‚ä¿¡æ¯ä¸­è§£æåˆ° ${audioSegments.length} ä¸ªç« èŠ‚æ ‡è®°`);
              } else {
                  const audioDuration = metadata.format.duration || 0;
                  const xmpSegments = parseXmpCuePoints(metadata, audioDuration);
                  if (xmpSegments && xmpSegments.length > 0) {
                      audioSegments = xmpSegments;
                  } else {
                      totalMissedCount += targetLines.length;
                      console.warn(`File ${file.name} has no chapter markers (neither CHAP nor XMP CuePoint).`);
                      continue;
                  }
              }

              // 3. Decode audio and split into blobs
              const mainAudioBuffer = await audioContext.decodeAudioData(await file.arrayBuffer());
              const limit = Math.min(targetLines.length, audioSegments.length);
              
              for (let i = 0; i < limit; i++) {
                  const segment = audioSegments[i];
                  const lineInfo = targetLines[i];
                  
                  const { startTime, endTime } = segment;
                  const duration = endTime - startTime;
                  if (duration <= 0) continue;

                  const startSample = Math.floor(startTime * mainAudioBuffer.sampleRate);
                  const endSample = Math.floor(endTime * mainAudioBuffer.sampleRate);
                  const numSamples = endSample - startSample;
                  
                  const segmentBuffer = audioContext.createBuffer(
                      mainAudioBuffer.numberOfChannels,
                      numSamples,
                      mainAudioBuffer.sampleRate
                  );

                  for (let channel = 0; channel < mainAudioBuffer.numberOfChannels; channel++) {
                      const channelData = mainAudioBuffer.getChannelData(channel);
                      const segmentData = channelData.subarray(startSample, endSample);
                      segmentBuffer.copyToChannel(segmentData, channel);
                  }

                  const segmentBlob = bufferToWav(segmentBuffer);

                  // 4. Assign split blob to line
                  await assignAudioToLine(currentProject.id, lineInfo.chapterId, lineInfo.line.id, segmentBlob);
                  totalMatchedCount++;
              }
              totalMissedCount += Math.abs(targetLines.length - audioSegments.length);

          } catch (error) {
              console.error(`Error processing file ${file.name}:`, error);
          }
      }

      await audioContext.close();
      setIsCharacterMatchLoading(false);
      alert(`æŒ‰è§’è‰²åŒ¹é…å®Œæˆã€‚\næˆåŠŸåŒ¹é…: ${totalMatchedCount} æ¡éŸ³è½¨\næœªåŒ¹é…/å¤±è´¥: ${totalMissedCount}`);
  
      if (event.target) {
          event.target.value = '';
      }
  }, [currentProject, characters, assignAudioToLine, nonAudioCharacterIds]);

  const handleFileSelectionForChapterMatch = useCallback(async (event: React.ChangeEvent<HTMLInputElement>) => {
    const files = event.target.files;
    if (!files || files.length === 0 || !currentProject) return;

    setIsChapterMatchLoading(true);

    let totalMatchedCount = 0;
    let totalMissedCount = 0;
    const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();

    for (const file of Array.from(files)) {
        const nameWithoutExt = file.name.substring(0, file.name.lastIndexOf('.'));
        const chapterIdentifier = nameWithoutExt;

        try {
            // 1. Find target script lines for this chapter range
            const chapterMatchers = parseChapterIdentifier(chapterIdentifier);
            const targetChapters = currentProject.chapters.filter((chapter, index) => {
                const chapterNumber = index + 1;
                return chapterMatchers.includes(chapterNumber);
            });

            if (targetChapters.length === 0) {
                console.warn(`No chapters found for identifier: ${chapterIdentifier}`);
                continue;
            }

            const targetLines: { line: ScriptLine; chapterId: string }[] = [];
            for (const chapter of targetChapters) {
                for (const line of chapter.scriptLines) {
                    if (!nonAudioCharacterIds.includes(line.characterId || '')) {
                        targetLines.push({ line, chapterId: chapter.id });
                    }
                }
            }
            
            if (targetLines.length === 0) {
                console.warn(`No lines found in chapters ${chapterIdentifier}`);
                continue;
            }

            // 2. Parse audio markers
            let metadata;
            try {
                metadata = await mm.parseBlob(file);
            } catch (parseError) {
                console.error(`Failed to parse metadata for ${file.name}:`, parseError);
                totalMissedCount += targetLines.length;
                continue;
            }

            let audioSegments: { startTime: number; endTime: number }[] = [];
            const chapters = metadata.common.chapters || [];

            if (chapters.length > 0) {
                audioSegments = chapters.map(chapter => ({
                    startTime: chapter.startTime / 1000,
                    endTime: chapter.endTime / 1000,
                }));
            } else {
                const audioDuration = metadata.format.duration || 0;
                const xmpSegments = parseXmpCuePoints(metadata, audioDuration);
                if (xmpSegments && xmpSegments.length > 0) {
                    audioSegments = xmpSegments;
                } else {
                    totalMissedCount += targetLines.length;
                    console.warn(`File ${file.name} has no chapter markers.`);
                    continue;
                }
            }

            // 3. Decode audio and split into blobs
            const mainAudioBuffer = await audioContext.decodeAudioData(await file.arrayBuffer());
            const limit = Math.min(targetLines.length, audioSegments.length);
            
            for (let i = 0; i < limit; i++) {
                const segment = audioSegments[i];
                const lineInfo = targetLines[i];
                
                const { startTime, endTime } = segment;
                const duration = endTime - startTime;
                if (duration <= 0) continue;

                const startSample = Math.floor(startTime * mainAudioBuffer.sampleRate);
                const endSample = Math.floor(endTime * mainAudioBuffer.sampleRate);
                const numSamples = endSample - startSample;
                
                const segmentBuffer = audioContext.createBuffer(
                    mainAudioBuffer.numberOfChannels,
                    numSamples,
                    mainAudioBuffer.sampleRate
                );

                for (let channel = 0; channel < mainAudioBuffer.numberOfChannels; channel++) {
                    const channelData = mainAudioBuffer.getChannelData(channel);
                    const segmentData = channelData.subarray(startSample, endSample);
                    segmentBuffer.copyToChannel(segmentData, channel);
                }

                const segmentBlob = bufferToWav(segmentBuffer);

                // 4. Assign split blob to line
                await assignAudioToLine(currentProject.id, lineInfo.chapterId, lineInfo.line.id, segmentBlob);
                totalMatchedCount++;
            }
            totalMissedCount += Math.abs(targetLines.length - audioSegments.length);

        } catch (error) {
            console.error(`Error processing file ${file.name}:`, error);
        }
    }

    await audioContext.close();
    setIsChapterMatchLoading(false);
    alert(`æŒ‰ç« èŠ‚åŒ¹é…å®Œæˆã€‚\næˆåŠŸåŒ¹é…: ${totalMatchedCount} æ¡éŸ³è½¨\næœªåŒ¹é…/å¤±è´¥: ${totalMissedCount}`);

    if (event.target) {
        event.target.value = '';
    }
  }, [currentProject, assignAudioToLine, nonAudioCharacterIds]);

  return {
    isCvMatchLoading,
    handleFileSelectionForCvMatch,
    isCharacterMatchLoading,
    handleFileSelectionForCharacterMatch,
    isChapterMatchLoading,
    handleFileSelectionForChapterMatch,
  };
};
